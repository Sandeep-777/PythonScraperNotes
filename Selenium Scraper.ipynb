{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium can be used to scrape websites which cannot be crawled using Beautiful soup and Urllib. These websites usually load content dynamically.\n",
    "<br>\n",
    "<b>Selenium WebDriver tool</b> is used to automate web application which can open browsers such as Chrome, Firefox, Chrome, Safari and so on.\n",
    "<br>\n",
    "<b>ActionChains</b> allows automating low level interactions like mouse movements, mouse button actions , key presses and context menu interactions.\n",
    "<br>\n",
    "<b>WebDriverWait</b> allows waiting until the element in a website is loaded or you expect something to happen. Check more about conditions <a href=\"https://selenium-python.readthedocs.io/waits.html\">here</a>.\n",
    "<br>\n",
    "<b>expected_conditions</b> allows us to check if condtions are met or not, such as if item is present, or if item is visible and so on.\n",
    "<br>\n",
    "<b>TimeoutException</b> is shown when element is not found in a specified time peroid\n",
    "<br>\n",
    "<b>NoSuchElementException</b> is shown when element does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a class to create objects which will be later used to store scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item():\n",
    "    def __init__(self, product_name, original_price, current_price, discount, rating, no_of_rating, image_source, product_url):\n",
    "        self.product_name = product_name\n",
    "        self.original_price = original_price\n",
    "        self.current_price = current_price\n",
    "        self.discount = discount\n",
    "        self.rating = rating\n",
    "        self.no_of_rating = no_of_rating\n",
    "        self.image_source = image_source\n",
    "        self.product_url = product_url\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'match score': self.product_name,\n",
    "            'original price': self.original_price,\n",
    "            'current price': self.current_price,\n",
    "            'discount': self.discount,\n",
    "            'rating': self.rating,\n",
    "            'number of rating': self.no_of_rating,\n",
    "            'image source': self.image_source,\n",
    "            'product url': self.product_url\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the delay to wait for element to wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELAY = 25\n",
    "URL = 'https://www.newegg.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifying list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['acer', 'dell']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the chrome driver and load the URL. Wait for the elements to appear and send keywords and submit. Get the results and traverse along pages. After getting the result from all pages then close the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rawdata(driver, keyword):\n",
    "    product_list = []\n",
    "    count = 0\n",
    "    try:\n",
    "        if count == 0:\n",
    "            searchbar =  WebDriverWait(driver, DELAY).until(EC.presence_of_element_located((By.ID, \"haQuickSearchBox\")))\n",
    "            searchbar.send_keys(keyword)\n",
    "            searchbar.submit()\n",
    "        \n",
    "        dropdown = WebDriverWait(driver, DELAY).until(EC.presence_of_element_located((By.ID, \"Order_top\")))\n",
    "        best_selling = dropdown.find_element_by_xpath('//option[text()=\"Best Selling\"]')\n",
    "        best_selling.click()\n",
    "        \n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        isNext = True\n",
    "        while isNext:\n",
    "            try:\n",
    "                nextbtn =  WebDriverWait(driver, DELAY).until(EC.presence_of_element_located((By.XPATH, '//button[contains(@title, \"Next\")]')))\n",
    "                if nextbtn.is_enabled():\n",
    "                    nextbtn.click()\n",
    "                else:\n",
    "                    isNext = False\n",
    "                count += 1\n",
    "                if count >5:\n",
    "                    isNext = False\n",
    "            except StaleElementReferenceException:\n",
    "                driver.implicitly_wait(10)                        \n",
    "            except NoSuchElementException:\n",
    "                isNext = False;\n",
    "        container = WebDriverWait(driver, DELAY).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"is-grid\")]')))\n",
    "        containers = driver.find_elements_by_xpath('//div[contains(@class, \"is-grid\")]')\n",
    "        #get data\n",
    "        for container in containers:\n",
    "            rawData = container.get_attribute('outerHTML')\n",
    "            bs = BeautifulSoup(rawData, 'html.parser')\n",
    "            item_lists = bs.select('div.item-container')\n",
    "            for item in item_lists:\n",
    "                product_url_container = item.select_one('a.item-title')\n",
    "                product_url = product_url_container['href']\n",
    "                product_name = product_url_container.get_text().strip()\n",
    "                product_image = item.find('img')['src']\n",
    "                rating_value = np.nan\n",
    "                previous_price_value = np.nan\n",
    "                current_price_value = np.nan\n",
    "                discount_value = np.nan\n",
    "                num_rating = np.nan\n",
    "                \n",
    "                rating_container = item.find('i', {'class': 'rating'})\n",
    "                if rating_container is not None:\n",
    "                    rating_value = int(rating_container['class'][-1].split('-')[-1])\n",
    "                num_rating_container = item.select_one('span.item-rating-num')  \n",
    "                if num_rating_container is not None:\n",
    "                    num_rating = num_rating_container.get_text().strip().replace('(','').replace(')','') \n",
    "                \n",
    "                previous_price = item.select_one('span.price-was-data')\n",
    "                if previous_price is not None:\n",
    "                    previous_price_value = previous_price.get_text().strip()\n",
    "                current_price = item.select_one('li.price-current')\n",
    "                if current_price is not None:\n",
    "                    dollars = current_price.find('strong').get_text().strip()\n",
    "                    cents = current_price.find('sup').get_text().strip()\n",
    "                    current_price_value = dollars+cents\n",
    "                discount = item.select_one('span.price-save-percent')\n",
    "                if discount is not None:\n",
    "                    discount_value = discount.get_text().strip()\n",
    "                product = Item(product_name, previous_price_value, current_price_value, discount_value, rating_value, num_rating, product_image, product_url)\n",
    "                product_list.append(product)\n",
    "    except TimeoutException:\n",
    "        print(\"Loading took too much time!\")\n",
    "    return product_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the rawdata obtained into required fields. Use the class created above to create objects with all the info and create a list of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple function to combine functions above so that the code is more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(URL, keywords):\n",
    "    product_list = []\n",
    "    driver = webdriver.Chrome()\n",
    "    for keyword in keywords:\n",
    "        driver.get(URL)\n",
    "        product_list.extend(get_rawdata(driver, keyword))\n",
    "    driver.close()\n",
    "    return product_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the list of projects using the combined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = get_all_data(URL, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>create a dataframe and clean the data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  current price discount                                       image source  \\\n",
      "0      1,299.00      32%  https://c1.neweggimages.com/ProductImageCompre...   \n",
      "1        219.73      NaN  https://c1.neweggimages.com/ProductImageCompre...   \n",
      "2        889.99      19%  https://c1.neweggimages.com/ProductImageCompre...   \n",
      "3        639.99      19%  https://c1.neweggimages.com/ProductImageCompre...   \n",
      "4      1,049.00      38%  https://c1.neweggimages.com/ProductImageCompre...   \n",
      "\n",
      "                                         match score number of rating  \\\n",
      "0  Acer Nitro 50 Gaming Desktop,8th Gen Intel Cor...              NaN   \n",
      "1  Acer TravelMate B1 B118-M TMB118-M-C80T 11.6\" ...              NaN   \n",
      "2  Acer Nitro 50 Desktop, Intel 6-Core i5-8400 Up...              NaN   \n",
      "3  Acer Aspire TC-885 Desktop, Intel 6-Core i5-84...                1   \n",
      "4  Acer Aspire GX Gaming Desktop,AMD Ryzen 7 1700...              NaN   \n",
      "\n",
      "  original price                                        product url  rating  \n",
      "0        1899.00  https://www.newegg.com/acer-nitro-n50-600-gami...     NaN  \n",
      "1            NaN  https://www.newegg.com/p/N82E16834316681?Descr...     NaN  \n",
      "2        1099.99  https://www.newegg.com/acer-nitro-n50-600-gami...     NaN  \n",
      "3         789.99  https://www.newegg.com/acer-aspire-tc-885-stud...     5.0  \n",
      "4        1699.00  https://www.newegg.com/acer-aspire-gx-281-ur13...     NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records([product_item.to_dict() for product_item in product_list])\n",
    "df.to_csv('new_egg_data.csv', index = False)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
